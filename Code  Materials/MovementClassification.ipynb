{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MovementClassification.ipynb","provenance":[],"authorship_tag":"ABX9TyMDOFOw1siCVGFXduH1euRd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"XwL36ClcXDHA"},"outputs":[],"source":["import tensorflow.keras\n","from PIL import Image, ImageOps\n","import numpy as np\n","import json\n","\n","\n","def analyseMainFrames(imageList):\n","    analyzedData = {}\n","    # Disable scientific notation for clarity\n","    np.set_printoptions(suppress=True)\n","    LABELS = [\"stance\", \"leg-movement\", \"glove-movement\"]\n","    STANCE_LABELS = [\"close\", \"top\"]\n","    LM_LABELS = [\"fine\", \"full-crouch\"]\n","    EXE_LABELS = [\"full-crouch\", \"fine-crouch\", \"fine-intercept\"]\n","    # Load the model\n","    modelStance = tensorflow.keras.models.load_model('converted_keras/converted_keras_stance/keras_model.h5')\n","    modelLegMovement = tensorflow.keras.models.load_model('converted_keras/converted_keras_legMovement/keras_model.h5')\n","    modelGloveMovement = tensorflow.keras.models.load_model('converted_keras/converted_keras_gloveMovement/keras_model.h5')\n","\n","    # Create the array of the right shape to feed into the keras model\n","    # The 'length' or number of images you can put into the array is\n","    # determined by the first position in the shape tuple, in this case 1.\n","    data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)\n","\n","    for label in LABELS:\n","        # Replace this with the path to your image\n","        image = Image.open(imageList[label])\n","\n","        # resize the image to a 224x224 with the same strategy as in TM2:\n","        # resizing the image to be at least 224x224 and then cropping from the center\n","        size = (224, 224)\n","        image = ImageOps.fit(image, size, Image.ANTIALIAS)\n","\n","        # turn the image into a numpy array\n","        image_array = np.asarray(image)\n","\n","        # display the resized image\n","        # image.show()\n","\n","        # Normalize the image\n","        normalized_image_array = (image_array.astype(np.float32) / 127.0) - 1\n","\n","        # Load the image into the array\n","        data[0] = normalized_image_array\n","\n","        # run the inference\n","        if label == 'stance':\n","            print(\"STANCE ANALYSIS\")\n","            prediction = modelStance.predict(data)\n","            print(prediction)\n","            idxs = prediction.argmax(axis=-1)\n","            for (i, j) in enumerate(idxs):\n","                print(STANCE_LABELS[j])\n","                analyzedData[\"stance\"] = STANCE_LABELS[j]\n","        if label == 'leg-movement':\n","            print(\"LM ANALYSIS\")\n","            prediction = modelLegMovement.predict(data)\n","            print(prediction)\n","            idxs = prediction.argmax(axis=-1)\n","            for (i, j) in enumerate(idxs):\n","                print(LM_LABELS[j])\n","                analyzedData[\"leg-movement\"] = LM_LABELS[j]\n","        if label == 'glove-movement':\n","            print(\"EXE ANALYSIS\")\n","            prediction = modelExecution.predict(data)\n","            print(prediction)\n","            idxs = prediction.argmax(axis=-1)\n","            for (i, j) in enumerate(idxs):\n","                print(EXE_LABELS[j])\n","                analyzedData[\"glove-movement\"] = EXE_LABELS[j]\n","    json_data = json.dumps(analyzedData)\n","    return json_data"]}]}