{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TechniqueAnalyzer.ipynb","provenance":[],"authorship_tag":"ABX9TyPEHCRojRUmMssbVhVzmfmj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"VbTIczp7YZ1L"},"outputs":[],"source":["import cv2\n","import time\n","import numpy as np\n","from imutils import paths\n","from PIL import Image, ImageOps\n","import os,shutil\n","import json\n","import tensorflow.keras\n","import cv2\n","from PIL import Image, ImageOps\n","\n","model = tensorflow.keras.models.load_model('converted_keras/keras_modelfinal1.h5', compile=False)\n","\n","\n","def classifyFrames(image,count):\n","\n","    np.set_printoptions(suppress=True)\n","\n","    LABELS = [\"stance\", \"leg-movement\", \"glove-movement\"]\n","\n","    # Create the array of the right shape to feed into the keras model\n","    # The 'length' or number of images you can put into the array is\n","    # determined by the first position in the shape tuple, in this case 1.\n","    data = np.ndarray(shape=(1, 224, 224, 3), dtype=np.float32)\n","\n","    # Replace this with the path to your image\n","    # imagePaths = sorted(list(paths.list_images(args[\"dataset\"])))\n","\n","    if image:\n","        # resize the image to a 224x224 with the same strategy as in TM2:\n","        # resizing the image to be at least 224x224 and then cropping from the center\n","        size = (224, 224)\n","        image = ImageOps.fit(image, size, Image.ANTIALIAS)\n","\n","        # turn the image into a numpy array\n","        image_array = np.asarray(image)\n","\n","        # Normalize the image\n","        normalized_image_array = (image_array.astype(np.float32) / 127.0) - 1\n","\n","        # Load the image into the array\n","        data[0] = normalized_image_array\n","\n","        # run the inference\n","        prediction = model.predict(data)\n","        idxs = prediction.argmax(axis=-1)\n","\n","        # print(\"idxs\",idxs)\n","        for (i, j) in enumerate(idxs):\n","            print(LABELS[j]+\"_frame\"+str(count))\n","            return LABELS[j]+\"_frame\"+str(count)\n","\n","\n","\n","def classifyMainFrames():\n","    args = {'dataset': 'stage1-output-frames'}\n","    if os.path.exists('ClassifiedFrames/execution') and os.path.exists('ClassifiedFrames/stance') \\\n","            and os.path.exists('ClassifiedFrames/leg-movement'):\n","        shutil.rmtree('ClassifiedFrames/leg-movement')\n","        os.makedirs('ClassifiedFrames/leg-movement')\n","        shutil.rmtree('ClassifiedFrames/stance')\n","        os.makedirs('ClassifiedFrames/stance')\n","        shutil.rmtree('ClassifiedFrames/glove-movement')\n","        os.makedirs('ClassifiedFrames/glove-movement')\n","    else:\n","        os.makedirs('ClassifiedFrames/glove-movement')\n","        os.makedirs('ClassifiedFrames/leg-movement')\n","        os.makedirs('ClassifiedFrames/stance')\n","    MODE = \"COCO\"\n","\n","    if MODE is \"COCO\":\n","        protoFile = \"pose/coco/pose_deploy_linevec.prototxt\"\n","        weightsFile = \"pose/coco/pose_iter_440000.caffemodel\"\n","        nPoints = 18\n","        # POSE_PAIRS = [[1, 0], [1, 2], [1, 5], [2, 3], [3, 4], [5, 6], [6, 7], [1, 8], [8, 9], [9, 10], [1, 11], [11, 12],\n","        #               [12, 13], [0, 14], [0, 15], [14, 16], [15, 17]]\n","        POSE_PAIRS = [[1, 17], [1, 2], [1, 5], [2, 3], [3, 4], [5, 6], [6, 7], [1, 8], [8, 9], [9, 10], [1, 11],\n","                      [11, 12],\n","                      [12, 13], [1, 16]]\n","\n","\n","\n","    elif MODE is \"MPI\":\n","        protoFile = \"pose/mpi/pose_deploy_linevec_faster_4_stages.prototxt\"\n","        weightsFile = \"pose/mpi/pose_iter_160000.caffemodel\"\n","        nPoints = 15\n","        POSE_PAIRS = [[0, 1], [1, 2], [2, 3], [3, 4], [1, 5], [5, 6], [6, 7], [1, 14], [14, 8], [8, 9], [9, 10],\n","                      [14, 11],\n","                      [11, 12], [12, 13]]\n","    colorz = [[0, 247, 255], [255, 225, 23], [0, 171, 255], [0, 247, 255], [0, 247, 255], [0, 171, 255],\n","              [239, 0, 255], [239, 0, 255], [68, 255, 0], [0, 247, 255], [0, 247, 255], [68, 255, 0],\n","              [239, 0, 255], [239, 0, 255], [0, 247, 255], [239, 0, 255], [0, 247, 255], [239, 0, 255]]\n","\n","    keypointsMapping = ['Nose', 'Neck', 'R-Sho', 'R-Elb', 'R-Wr', 'L-Sho',\n","                        'L-Elb', 'L-Wr', 'R-Hip', 'R-Knee', 'R-Ank', 'L-Hip',\n","                        'L-Knee', 'L-Ank', 'R-Eye', 'L-Eye', 'R-Ear', 'L-Ear']\n","\n","    if os.path.exists('keypoints-detected-frames/skeleton-with-image'):\n","        shutil.rmtree('keypoints-detected-frames/skeleton-with-image')\n","        os.makedirs('keypoints-detected-frames/skeleton-with-image')\n","    else:\n","        os.makedirs('keypoints-detected-frames/skeleton-with-image')\n","\n","    if os.path.exists('keypoints-detected-frames/skeleton-only'):\n","        shutil.rmtree('keypoints-detected-frames/skeleton-only')\n","        os.makedirs('keypoints-detected-frames/skeleton-only')\n","    else:\n","        os.makedirs('keypoints-detected-frames/skeleton-only')\n","\n","    imagePaths = sorted(list(paths.list_images(args[\"dataset\"])))\n","    k = 1\n","\n","    stanceCount = 1\n","    legMovementCount = 1\n","    gloveMovementCount = 1\n","    stanceArray = []\n","    legMovementArray = []\n","    gloveMovementArray = []\n","    classifiedData = {}\n","    classifiedData[\n","        'baseUrl'] = \"/content/drive/MyDrive/FYP/output\"\n","    # --------------------------------\n","    for imagePath in imagePaths:\n","        # print(\"Reading Image :\", imagePath)\n","        frame = cv2.imread(\"stage1-output-frames/frame\" + str(k) + \".jpg\")\n","        frameCopy = np.copy(frame)\n","        frameWidth = frame.shape[1]\n","        frameHeight = frame.shape[0]\n","        threshold = 0.1\n","\n","        net = cv2.dnn.readNetFromCaffe(protoFile, weightsFile)\n","\n","        t = time.time()\n","        # input image dimensions for the network\n","        inWidth = 368\n","        inHeight = 368\n","        inpBlob = cv2.dnn.blobFromImage(frame, 1.0 / 255, (inWidth, inHeight),\n","                                        (0, 0, 0), swapRB=False, crop=False)\n","\n","        net.setInput(inpBlob)\n","\n","        output = net.forward()\n","\n","        height, width = 700, 500\n","        keypointsOnlyFrame = np.zeros((height, width, 3), dtype=\"uint8\")\n","        keypointsOnlyFrame.fill(255)\n","\n","        H = output.shape[2]\n","        W = output.shape[3]\n","\n","        # Empty list to store the detected keypoints\n","        points = []\n","        pointOnlyFrame = []\n","        for i in range(nPoints):\n","\n","            # confidence map of corresponding body's part.\n","            probMap = output[0, i, :, :]\n","\n","            # Find global maxima of the probMap.\n","            minVal, prob, minLoc, point = cv2.minMaxLoc(probMap)\n","            if i != 0 and i != 14 and i != 15:\n","                # Scale the point to fit on the original image\n","                x = (frameWidth * point[0]) / W\n","                y = (frameHeight * point[1]) / H\n","                xk = (width * point[0]) / W\n","                yk = (height * point[1]) / H\n","                if prob > threshold:\n","                    cv2.circle(keypointsOnlyFrame, (int(xk), int(yk)), 5, (13, 29, 181), thickness=-1,\n","                               lineType=cv2.FILLED)\n","                    cv2.circle(frame, (int(x), int(y)), 8, (0, 255, 255), thickness=-1, lineType=cv2.FILLED)\n","                    cv2.putText(frame, \"{}\".format(i), (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2,\n","                                lineType=cv2.LINE_AA)\n","\n","                    # Add the point to the list if the probability is greater than the threshold\n","                    points.append((int(x), int(y)))\n","                    pointOnlyFrame.append((int(xk), int(yk)))\n","                else:\n","                    points.append(None)\n","                    pointOnlyFrame.append(None)\n","            else:\n","                points.append(None)\n","                pointOnlyFrame.append(None)\n","        # Draw Skeleton\n","        for pair in POSE_PAIRS:\n","\n","            partA = pair[0]\n","            partB = pair[1]\n","            if points[partA] and points[partB]:\n","                cv2.line(keypointsOnlyFrame, pointOnlyFrame[partA], pointOnlyFrame[partB], (242, 112, 16), 2)\n","                cv2.line(frame, points[partA], points[partB], (0, 255, 255), 2)\n","                # cv2.circle(frame, points[partA], 8, (0, 0, 255), thickness=-1, lineType=cv2.FILLED)\n","\n","        # You may need to convert the color.\n","        img = cv2.cvtColor(keypointsOnlyFrame, cv2.COLOR_BGR2RGB)\n","        im_pil = Image.fromarray(img)\n","\n","        # For reversing the operation:\n","        im_np = np.asarray(im_pil)\n","\n","        classifiedStage = classifyFrames(im_pil, k)\n","        imageRGB = cv2.imread(\"stage1-output-frames/\" + classifiedStage.split(\"_\")[1] + '.jpg')\n","        if \"stance\" == classifiedStage.split(\"_\")[0]:\n","            cv2.imwrite('ClassifiedFrames/' + classifiedStage.split(\"_\")[0] + \"/\" + \"frame\" + str(stanceCount) + '.jpg',\n","                        imageRGB)\n","            stanceArray.append(\"frame\" + str(stanceCount))\n","            stanceCount += 1\n","        if \"leg-movement\" == classifiedStage.split(\"_\")[0]:\n","            cv2.imwrite(\n","                'ClassifiedFrames/' + classifiedStage.split(\"_\")[0] + \"/\" + \"frame\" + str(legMovementCount) + '.jpg',\n","                imageRGB)\n","            legMovementArray.append(\"frame\" + str(legMovementCount))\n","            legMovementCount += 1\n","        if \"glove-movement\" == classifiedStage.split(\"_\")[0]:\n","            cv2.imwrite(\n","                'ClassifiedFrames/' + classifiedStage.split(\"_\")[0] + \"/\" + \"frame\" + str(gloveMovementCount) + '.jpg',\n","                imageRGB)\n","            gloveMovementArray.append(\"frame\" + str(gloveMovementCount))\n","            gloveMovementCount += 1\n","        k += 1\n","    #     -----------------------------\n","\n","    classifiedData[\"stance\"] = stanceArray\n","    classifiedData[\"leg-movement\"] = legMovementArray\n","    classifiedData[\"glove-movement\"] = gloveMovementArray\n","    json_data = json.dumps(classifiedData)\n","    return json_data"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EQyUbYALZxdL","executionInfo":{"status":"ok","timestamp":1646204007243,"user_tz":-330,"elapsed":22705,"user":{"displayName":"Viduth Ishara","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhFXCphY8XqHWvWKAJQRPSHTXi7Ij6PrP5IxdwRcA=s64","userId":"17395933505961235457"}},"outputId":"ad34b230-4f2f-46a1-f549-b73465c31d38"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]}]}